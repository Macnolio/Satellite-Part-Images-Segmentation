{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcN02XX9sYUD"
      },
      "source": [
        "#Setting up environment and preprocessing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSlHsIXCrwwS"
      },
      "source": [
        "##Installing needed packages and importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5z0TaOOrad4",
        "outputId": "60051ea4-4886-4c83-fd89-812e116eb2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Macnolio/Satellite-Part-Images-Segmentation\n",
            "  Cloning https://github.com/Macnolio/Satellite-Part-Images-Segmentation to /tmp/pip-req-build-1g7mik1d\n",
            "  Running command git clone -q https://github.com/Macnolio/Satellite-Part-Images-Segmentation /tmp/pip-req-build-1g7mik1d\n",
            "Collecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 22.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from keras-segmentation==0.3.0) (2.9.0)\n",
            "Collecting imageio==2.5.0\n",
            "  Downloading imageio-2.5.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from keras-segmentation==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from keras-segmentation==0.3.0) (4.6.0.66)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from keras-segmentation==0.3.0) (4.64.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio==2.5.0->keras-segmentation==0.3.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.5.0->keras-segmentation==0.3.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py<=2.10.0->keras-segmentation==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->keras-segmentation==0.3.0) (2.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->keras-segmentation==0.3.0) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->keras-segmentation==0.3.0) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->keras-segmentation==0.3.0) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->keras-segmentation==0.3.0) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->keras-segmentation==0.3.0) (2.8.8)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->keras-segmentation==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (2.8.2)\n",
            "Building wheels for collected packages: keras-segmentation\n",
            "  Building wheel for keras-segmentation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-segmentation: filename=keras_segmentation-0.3.0-py3-none-any.whl size=34604 sha256=5e872f80aad8a2e1dd1c9e62fde74ae87b662a2710e6e703eca7f54d1f69c1dc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5osr0oe3/wheels/9a/fb/1b/02d07fcd8b1265c2f71d8c6855e217cc87bce58ece9208e58c\n",
            "Successfully built keras-segmentation\n",
            "Installing collected packages: imageio, h5py, keras-segmentation\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0 imageio-2.5.0 keras-segmentation-0.3.0\n"
          ]
        }
      ],
      "source": [
        "# GitHub with the Python codes for Keras segmentation models:\n",
        "! pip install git+https://github.com/Macnolio/Satellite-Part-Images-Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnmsjysMsMRg"
      },
      "source": [
        "##Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhIQQTausmC5",
        "outputId": "494356c5-3ac9-4566-90f7-7b4e39cea148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Personal Drive into Google Collab: Before upload the Final_Dataset.rar to your personal drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Asking for download of the dataset:\n",
        "import requests\n",
        "file_url = \"https://drive.google.com/file/d/1x0zBjpGVBorbFLjpcIlK8Wr1E68yTYL7/view?usp=sharing\" #Share link of the dataset, change it to your own link\n",
        "\n",
        "r = requests.get(file_url, stream = True)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/python.pdf\", \"wb\") as file:\n",
        "    for block in r.iter_content(chunk_size = 1024):\n",
        "         if block:\n",
        "             file.write(block)\n",
        "\n",
        "# Other option if you are the main user of the drive: It starts failing when too it is used many times\n",
        "#!gdown 1x0zBjpGVBorbFLjpcIlK8Wr1E68yTYL7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irqK-YWBs7p4"
      },
      "outputs": [],
      "source": [
        "#Copying file from the personal drive to collab folder, for easier access:\n",
        "!cp \"/content/gdrive/MyDrive/Final_dataset.rar\" \"/content/Final_dataset.rar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3rmr4bxs-TA"
      },
      "outputs": [],
      "source": [
        "# Unzipping the dataset\n",
        "!unrar x Final_dataset.rar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvdbGHDttWkC"
      },
      "source": [
        "## Preprocessing the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6tLa9JtteLX"
      },
      "source": [
        "### Training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an7WOw8btbOt"
      },
      "outputs": [],
      "source": [
        "# Importing image and arrays manipulation libraries:\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "# Renaming masks: Images and masks must have the same name to allow the training function to detect the solution masks\n",
        "collection = \"Final_dataset/train/masks/\"\n",
        "new_name = \"Final_dataset/train/images/\"\n",
        "i = 0\n",
        "for i, filename in enumerate(os.listdir(collection)):\n",
        "    old_name = filename\n",
        "    fixed_name = filename.replace(\"_mask\",\"\")\n",
        "    os.rename(\"Final_dataset/train/masks/\" + old_name , \"Final_dataset/train/masks/\" + fixed_name)\n",
        "\n",
        "#Normalizing and resizing training dataset:\n",
        "# Masks:\n",
        "mask_path = \"Final_dataset/train/masks/\"\n",
        "i = 0\n",
        "for i, filename in enumerate(os.listdir(mask_path)):\n",
        "    name = filename\n",
        "    img = cv.imread(mask_path + name)         # Original masks go between 0 y 11\n",
        "    # Resizing\n",
        "    img = cv.resize(img, (576,320), interpolation = cv.INTER_NEAREST) # The images size must be divisible by 32, no other restriction. Reducing the size for reducing training computation cost\n",
        "    #Reasigning pixel values to each class: The Keras functions work with a unique number in all the RGB channels\n",
        "    img[np.all(img == (255, 0, 0), axis=-1)] = (1,1,1) #Antenna\n",
        "    img[np.all(img == (0, 255, 0), axis=-1)] = (2,2,2) #Body\n",
        "    img[np.all(img == (0, 0, 255), axis=-1)] = (3,3,3) #Solar panel\n",
        "    # Saving\n",
        "    cv.imwrite(mask_path + name, img)\n",
        "\n",
        "# Images:\n",
        "images_path = \"Final_dataset/train/images/\"\n",
        "i = 0\n",
        "for i, filename in enumerate(os.listdir(images_path)):\n",
        "    name = filename\n",
        "    img = cv.imread(images_path + name)\n",
        "    img = cv.resize(img, (576,320))                        #No need for resizing, the images must be RGB from [0:255] values\n",
        "    cv.imwrite(images_path + name, img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn8Y7Lpctilm"
      },
      "source": [
        "###Validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhMB2Xo5-fkx"
      },
      "outputs": [],
      "source": [
        "# Importing image and arrays manipulation libraries:\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "# Renaming masks: Images and masks must have the same name to allow the training function to detect the solution masks\n",
        "collection = \"Final_dataset/val/masks/\"\n",
        "new_name = \"Final_dataset/val/images/\"\n",
        "i = 0\n",
        "for i, filename in enumerate(os.listdir(collection)):\n",
        "    old_name = filename\n",
        "    fixed_name = filename.replace(\"_mask\",\"\")\n",
        "    os.rename(\"Final_dataset/val/masks/\" + old_name , \"Final_dataset/val/masks/\" + fixed_name)\n",
        "\n",
        "#Normalizing and resizing training dataset:\n",
        "# Masks:\n",
        "mask_path = \"Final_dataset/val/masks/\"\n",
        "i = 0\n",
        "for i, filename in enumerate(os.listdir(mask_path)):\n",
        "    name = filename\n",
        "    img = cv.imread(mask_path + name)        #Original masks go between 0 y 11\n",
        "    # Resizing\n",
        "    img = cv.resize(img, (576,320), interpolation = cv.INTER_NEAREST) # The images size must be divisible by 32, no other restriction. Reducing the size for reducing training computation cost\n",
        "    #Reasigning pixel values to each class: The Keras functions work with a unique number in all the RGB channels\n",
        "    img[np.all(img == (255, 0, 0), axis=-1)] = (1,1,1) #Antenna\n",
        "    img[np.all(img == (0, 255, 0), axis=-1)] = (2,2,2) #Body\n",
        "    img[np.all(img == (0, 0, 255), axis=-1)] = (3,3,3) #Solar panel    Tenia axis -1\n",
        "    # Saving\n",
        "    cv.imwrite(mask_path + name, img)\n",
        "\n",
        "# Images:\n",
        "images_path = \"Final_dataset/val/images/\"\n",
        "i = 0\n",
        "for i, filename in enumerate(os.listdir(images_path)):\n",
        "    name = filename\n",
        "    img = cv.imread(images_path + name)\n",
        "    img = cv.resize(img, (576,320))                           #No need for resizing, the images must be RGB from [0:255] values\n",
        "    cv.imwrite(images_path + name, img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZLCsGqaxCzj"
      },
      "source": [
        "### Saving preprocessed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aNEe_OHxGlT"
      },
      "outputs": [],
      "source": [
        "# Saving the modified data: (I have it in my computer if needed can be imported directly, to skip steps)\n",
        "## Zipping data\n",
        "# !zip -r /content/Final_dataset.zip /content/Final_dataset\n",
        "## Downloading from google colab:\n",
        "# from google.colab import files\n",
        "# files.download(\"Final_dataset.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Copying file from the personal drive to collab folder, for easier access:\n",
        "# !cp \"/content/Final_dataset.zip\" \"/content/gdrive/MyDrive/Final_dataset.zip\" "
      ],
      "metadata": {
        "id": "0jOsyH_kww1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS4kJQw7xQmR"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dwHfQX5xPul"
      },
      "outputs": [],
      "source": [
        "# Importing model from keras_segmentation:\n",
        "from keras_segmentation.models.fcn import fcn_8_mobilenet\n",
        "# Initialising the model:\n",
        "model = fcn_8_mobilenet(n_classes=4 ,  input_height=320, input_width=576)   # Remember: Same size as the resizing\n",
        "\n",
        "# Check all models in all_models.py: The input size values msut be divisible between 32!!\n",
        "##from keras_segmentation.models.pspnet import pspnet (Resize to 192 multiple, it only works like that)\n",
        "##from keras_segmentation.models.pspnet import unet\n",
        "##from keras_segmentation.models.fcn import fcn_8_mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTXWADzNxu9M"
      },
      "outputs": [],
      "source": [
        "#Summary of the model:\n",
        "model.summary()     #Prints a table with the model layers "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfZx763Rx9o1"
      },
      "source": [
        "#Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyH1lDAGyCjw"
      },
      "source": [
        "##Setting up enviroment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSLYcrUXyP3b"
      },
      "source": [
        "###Monitoring and Stopping options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-zTz0oxxzUW"
      },
      "outputs": [],
      "source": [
        "# Monitoring and callbacks activation: If the validation_loss keeps increasing, the training is stopped. This aloows to avoid overweight.\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",\n",
        "\t\t\t\t\t\t\t\t\t\tmode =\"min\", patience = 5,\n",
        "\t\t\t\t\t\t\t\t\t\trestore_best_weights = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFUTVPyUypLn"
      },
      "source": [
        "### Data Augmentation options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wXRvGVAyOvd"
      },
      "outputs": [],
      "source": [
        "#Importing data augmentation library:\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# Available augmentations:\n",
        "# augmentation_functions = {\n",
        "#     \"aug_all\": _load_augmentation_aug_all,\n",
        "#     \"aug_all2\": _load_augmentation_aug_all2,\n",
        "#     \"aug_geometric\": _load_augmentation_aug_geometric,\n",
        "#     \"aug_non_geometric\": _load_augmentation_aug_non_geometric\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBAJ7zZky7rD"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa0z1r_0y93n",
        "outputId": "05ac6c78-762b-43ac-8a3d-56dbf43550c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying training dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2517/2517 [00:19<00:00, 130.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset verified! \n",
            "Verifying validation dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [00:04<00:00, 126.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset verified! \n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 434s 4s/step - loss: 0.6706 - accuracy: 0.7457 - val_loss: 0.4319 - val_accuracy: 0.8417\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 415s 4s/step - loss: 0.2108 - accuracy: 0.9121 - val_loss: 0.2398 - val_accuracy: 0.9097\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 414s 4s/step - loss: 0.1511 - accuracy: 0.9458 - val_loss: 0.2144 - val_accuracy: 0.9262\n",
            "Epoch 4/10\n",
            " 60/100 [=================>............] - ETA: 2:07 - loss: 0.1144 - accuracy: 0.9601"
          ]
        }
      ],
      "source": [
        "# Using the Github:\n",
        "\n",
        "# Importing optimizers: \n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "# Training Model\n",
        "history = model.train(\n",
        "              train_images =  \"Final_dataset/train/images/\",\n",
        "              train_annotations = \"Final_dataset/train/masks/\",\n",
        "              n_classes = 4,\n",
        "              checkpoints_path = \"/tmp/fcn_8_mobilenet\",   \n",
        "              epochs=10,\n",
        "              batch_size=32,\n",
        "              validate=True,\n",
        "              val_images=\"Final_dataset/val/images/\",\n",
        "              val_annotations=\"Final_dataset/val/masks/\",\n",
        "              val_batch_size=32,\n",
        "              steps_per_epoch=100,\n",
        "              val_steps_per_epoch=100,\n",
        "              optimizer_name=Adam(learning_rate=1e-3),\n",
        "              do_augment=False,\n",
        "              augmentation_name=\"aug_all\",\n",
        "              callbacks=[earlystopping],\n",
        "              read_image_type=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzoiUh_C1aKX"
      },
      "source": [
        "# Predicting Segmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnhG04hc1fF-"
      },
      "source": [
        "## Only one Image prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YdA857f1m-G"
      },
      "outputs": [],
      "source": [
        "# Importing prediction colors:\n",
        "from keras_segmentation.data_utils.data_loader import class_colors\n",
        "\n",
        "# Changing class colors to make them as the original masks\n",
        "class_colors[0] = (0,0,0)      # Background                               # Current colors selected randomly with a constant seed:  \n",
        "class_colors[1] = (255,0,0)    # Antenna                                  #(197, 215, 20), (132, 248, 207), (155, 244, 183), (111, 71, 144)\n",
        "class_colors[2] = (0,255,0)    # Body\n",
        "class_colors[3] = (0,0,255)    # Solar Panel                                        \n",
        "\n",
        "# Predicting new segmentation:\n",
        "o = model.predict_segmentation(\n",
        "    inp=\"Final_dataset/val/images/img_resize_677.png\",                    # Choose image to be predicted\n",
        "    out_fname=\"/tmp/out.png\" , overlay_img=False, show_legends=True,      # overlay: Puts the original image behind\n",
        "    class_names = [ \"Background\", \"Antenna\",  \"Body\", \"Solar Panels\"])    # legends: Color and corresponding class\n",
        "                                                                            #438, 637,677\n",
        "#Printing image:\n",
        "from IPython.display import Image\n",
        "Image('/tmp/out.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qKbPqhw2ZNt"
      },
      "source": [
        "## Predicting a complete dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7vTS5_e297x"
      },
      "outputs": [],
      "source": [
        "from keras_segmentation.data_utils.data_loader import class_colors\n",
        "# Changing class colors to make them as the original masks: This is to be able to evaluate the model afterwards\n",
        "class_colors[0] = (0,0,0)    # Background\n",
        "class_colors[1] = (1,1,1)    # Antenna\n",
        "class_colors[2] = (2,2,2)    # Body\n",
        "class_colors[3] = (3,3,3)    # Solar Panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_p3h-1K2daX"
      },
      "outputs": [],
      "source": [
        "from keras_segmentation.predict import predict_multiple, predict\n",
        "predict_multiple(inp_dir=\"Final_dataset/val/images/\", checkpoints_path=\"/tmp/fcn_32_mobilenet\",out_dir=\"/tmp/prediction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwx8H5Q-2csg"
      },
      "source": [
        "# Evaluating the model predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1EYgx663UD5"
      },
      "source": [
        "## Fast Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQHRwJQpWHZO"
      },
      "outputs": [],
      "source": [
        "from keras_segmentation.data_utils.data_loader import class_colors\n",
        "# Changing class colors to make them as the original masks: This is to be able to evaluate the model afterwards\n",
        "class_colors[0] = (0,0,0)    # Background\n",
        "class_colors[1] = (1,1,1)    # Antenna\n",
        "class_colors[2] = (2,2,2)    # Body\n",
        "class_colors[3] = (3,3,3)    # Solar Panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fl4sFI-2nho"
      },
      "outputs": [],
      "source": [
        "val_image_dir = \"Final_dataset/val/images/\"\n",
        "val_masks_dir = \"Final_dataset/val/masks/\"\n",
        "from keras_segmentation.predict import evaluate\n",
        "ev = model.evaluate_segmentation(inp_images_dir=val_image_dir, annotations_dir=val_masks_dir)\n",
        "assert ev['frequency_weighted_IU'] > 0.01\n",
        "print(ev)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}